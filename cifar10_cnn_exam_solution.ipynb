{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_cnn_exam_solution.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/timohe/ML-Keras_ConvNeuralNet/blob/master/cifar10_cnn_exam_solution.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "CwL1HaHTuWLt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CIFAR10 with CNN\n",
        "code from https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n"
      ]
    },
    {
      "metadata": {
        "id": "tkM8NCnJuWLv",
        "colab_type": "raw"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook trains a simple convolutional neural network on the CIFAR10 small images dataset. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "S8UZFSsBuWLv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7dbb907-8ce8-404d-c254-715c4f272bdb"
      },
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from __future__ import print_function\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "#for confusion matrix\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HX32-SrFuWL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prepare data"
      ]
    },
    {
      "metadata": {
        "id": "o07n3FvbuWL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0379b628-356b-45f4-bb15-952638ec6048"
      },
      "cell_type": "code",
      "source": [
        "# define constants\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "# The data, shuffled and split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Cast features into correct data type then scale features\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 21s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cW5LnHj5uWL3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define model"
      ]
    },
    {
      "metadata": {
        "id": "YYl_mjtUuWL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7dab6634-41bb-4d34-c47d-49e9e27e5574"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MSNoYmMFuWL5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Show model structure"
      ]
    },
    {
      "metadata": {
        "id": "CF1UH3FsuWL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "6b79077a-e098-4eb4-9721-c184434fedde"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5LrNtCcXuWL9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compile model and fit\n"
      ]
    },
    {
      "metadata": {
        "id": "j--3W_mEuWL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "1be9071b-a851-406e-d795-2fb152baf7f9"
      },
      "cell_type": "code",
      "source": [
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            shuffle=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 15s 299us/step - loss: 1.9890 - acc: 0.2733 - val_loss: 1.7458 - val_acc: 0.3773\n",
            "Epoch 2/20\n",
            "20352/50000 [===========>..................] - ETA: 7s - loss: 1.7569 - acc: 0.3632"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.7134 - acc: 0.3822 - val_loss: 1.6298 - val_acc: 0.4109\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 1.5972 - acc: 0.4225 - val_loss: 1.4859 - val_acc: 0.4644\n",
            "Epoch 4/20\n",
            "32896/50000 [==================>...........] - ETA: 4s - loss: 1.5245 - acc: 0.4516"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.5088 - acc: 0.4570 - val_loss: 1.4500 - val_acc: 0.4727\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.4302 - acc: 0.4870 - val_loss: 1.3356 - val_acc: 0.5233\n",
            "Epoch 6/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.3735 - acc: 0.5112"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 253us/step - loss: 1.3679 - acc: 0.5132 - val_loss: 1.2703 - val_acc: 0.5476\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 1.3145 - acc: 0.5327 - val_loss: 1.2423 - val_acc: 0.5589\n",
            "Epoch 8/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.2674 - acc: 0.5497"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 253us/step - loss: 1.2645 - acc: 0.5515 - val_loss: 1.1815 - val_acc: 0.5799\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 1.2235 - acc: 0.5687 - val_loss: 1.1433 - val_acc: 0.5965\n",
            "Epoch 10/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.1860 - acc: 0.5810"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.1812 - acc: 0.5829 - val_loss: 1.1258 - val_acc: 0.6011\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 1.1374 - acc: 0.5997 - val_loss: 1.0812 - val_acc: 0.6212\n",
            "Epoch 12/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.1078 - acc: 0.6099"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 253us/step - loss: 1.1059 - acc: 0.6103 - val_loss: 1.0586 - val_acc: 0.6285\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 1.0775 - acc: 0.6211 - val_loss: 0.9928 - val_acc: 0.6549\n",
            "Epoch 14/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.0466 - acc: 0.6333"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.0467 - acc: 0.6323 - val_loss: 0.9848 - val_acc: 0.6521\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.0175 - acc: 0.6450 - val_loss: 0.9890 - val_acc: 0.6575\n",
            "Epoch 16/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 0.9988 - acc: 0.6508"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 254us/step - loss: 0.9960 - acc: 0.6523 - val_loss: 0.9409 - val_acc: 0.6770\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 0.9719 - acc: 0.6592 - val_loss: 0.9596 - val_acc: 0.6677\n",
            "Epoch 18/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 0.9559 - acc: 0.6655"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 255us/step - loss: 0.9530 - acc: 0.6654 - val_loss: 0.9257 - val_acc: 0.6759\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 0.9354 - acc: 0.6736 - val_loss: 0.8829 - val_acc: 0.6941\n",
            "Epoch 20/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 0.9161 - acc: 0.6794"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 254us/step - loss: 0.9138 - acc: 0.6806 - val_loss: 0.8781 - val_acc: 0.6973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8be6958f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "TnqygMfpuWMF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d9f07f41-5902-406e-9d44-a0b53675c15b"
      },
      "cell_type": "code",
      "source": [
        "# Save the original model\n",
        "model.save('cifra10_base.h5')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qjAnVrbjuWMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "8128ccfa-289f-483b-a2ce-d26c515b3704"
      },
      "cell_type": "code",
      "source": [
        "# Print base model loss and accuracy\n",
        "print('\\n  - Base case:')\n",
        "model = keras.models.load_model(\"cifra10_base.h5\")\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('\\tTest loss:\\t', scores[0])\n",
        "print('\\tTest accuracy:\\t', scores[1])\n",
        "Y_pred = model.predict(x_test, verbose=2)\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(Y_pred, axis=1))\n",
        "print('\\tConfusion Matrix:\\t')\n",
        "print(cm)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  - Base case:\n",
            "\tTest loss:\t 0.8781241746902466\n",
            "\tTest accuracy:\t 0.6973\n",
            "\tConfusion Matrix:\t\n",
            "[[733  29  39  18  24   6  10  12  56  73]\n",
            " [  4 841   2   4   4   1   8   4  10 122]\n",
            " [ 72   8 470  61 165  65  69  55  14  21]\n",
            " [ 19  13  51 468 121 147  68  60  14  39]\n",
            " [ 21   5  29  44 723  14  47  97  14   6]\n",
            " [  9  11  35 179  77 564  27  77   6  15]\n",
            " [  8   4  25  54  71  17 784  13   5  19]\n",
            " [ 10   5  18  23  85  46   5 781   2  25]\n",
            " [ 65  66  11  13   6   5   5   5 769  55]\n",
            " [ 16  77   4  10   8   3   6  18  18 840]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yt0xEddBmTsk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1) Augment the data by adding noise."
      ]
    },
    {
      "metadata": {
        "id": "AMBbUhcTuWMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "0887eb46-1b2f-437f-f47f-70067ceee99b"
      },
      "cell_type": "code",
      "source": [
        "# Save models with gaussian noise with different Standard Deviation\n",
        "for e in [0.5,0.1,0.05,0.02,0.01]:\n",
        "    \n",
        "    model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  #Add noise\n",
        "  model.add(keras.layers.GaussianNoise(e))\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  model.fit(x_train, y_train,\n",
        "                batch_size=batch_size,\n",
        "                epochs=epochs,\n",
        "                validation_data=(x_test, y_test),\n",
        "                shuffle=True)\n",
        "  model.save('cifra10_n'+str(e)+'.h5')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-4906f37589b7>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\u001b[0m\n\u001b[0m                                                                               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fVUkk-43uWML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "1e4d46a0-26cc-49dd-bc1e-75a83e9350df"
      },
      "cell_type": "code",
      "source": [
        "# Load models and print results\n",
        "for e in [0.5,0.1,0.05,0.02,0.01]:\n",
        "    model = keras.models.load_model('cifra10_n'+str(e)+'.h5')\n",
        "    print('\\n  - Gaussian Noise with '+str(e)+' stdev:')\n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('\\tTest loss:\\t', scores[0])\n",
        "    print('\\tTest accuracy:\\t', scores[1])\n",
        "    \n",
        "# Load and print of the best loss and accuracy obtained\n",
        "model = keras.models.load_model(\"cifra10_n0.02.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  - Gaussian Noise with 0.5 stdev:\n",
            "\tTest loss:\t 1.4783432458877563\n",
            "\tTest accuracy:\t 0.6273\n",
            "\n",
            "  - Gaussian Noise with 0.1 stdev:\n",
            "\tTest loss:\t 0.8635457564353943\n",
            "\tTest accuracy:\t 0.7043\n",
            "\n",
            "  - Gaussian Noise with 0.05 stdev:\n",
            "\tTest loss:\t 0.8434040348052978\n",
            "\tTest accuracy:\t 0.7109\n",
            "\n",
            "  - Gaussian Noise with 0.02 stdev:\n",
            "\tTest loss:\t 0.809952991771698\n",
            "\tTest accuracy:\t 0.727\n",
            "\n",
            "  - Gaussian Noise with 0.01 stdev:\n",
            "\tTest loss:\t 0.7354572436332703\n",
            "\tTest accuracy:\t 0.7488\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JsJqBNCqmTso",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2) Add layers to the network to improve performance"
      ]
    },
    {
      "metadata": {
        "id": "W-q-pZF-mTso",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### First model: batch normalization"
      ]
    },
    {
      "metadata": {
        "id": "f2KL0hWjuWMO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "ef1229c0-3b18-4933-dd08-5b8d40a7126c"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            shuffle=True)\n",
        "\n",
        "model.save('cifra10_batch.h5')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 18s 366us/step - loss: 1.9586 - acc: 0.3018 - val_loss: 1.5445 - val_acc: 0.4519\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 17s 346us/step - loss: 1.5717 - acc: 0.4245 - val_loss: 1.3776 - val_acc: 0.4983\n",
            "Epoch 3/20\n",
            " 8576/50000 [====>.........................] - ETA: 13s - loss: 1.4671 - acc: 0.4692"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 347us/step - loss: 1.4354 - acc: 0.4785 - val_loss: 1.2801 - val_acc: 0.5419\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 17s 347us/step - loss: 1.3556 - acc: 0.5091 - val_loss: 1.2319 - val_acc: 0.5636\n",
            "Epoch 5/20\n",
            "29312/50000 [================>.............] - ETA: 6s - loss: 1.3001 - acc: 0.5316"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 346us/step - loss: 1.2909 - acc: 0.5355 - val_loss: 1.1479 - val_acc: 0.5922\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 18s 350us/step - loss: 1.2318 - acc: 0.5585 - val_loss: 1.1558 - val_acc: 0.5878\n",
            "Epoch 7/20\n",
            "34176/50000 [===================>..........] - ETA: 5s - loss: 1.1901 - acc: 0.5721"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 348us/step - loss: 1.1776 - acc: 0.5772 - val_loss: 1.0543 - val_acc: 0.6280\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 17s 349us/step - loss: 1.1312 - acc: 0.5970 - val_loss: 1.1196 - val_acc: 0.6025\n",
            "Epoch 9/20\n",
            "35328/50000 [====================>.........] - ETA: 4s - loss: 1.0907 - acc: 0.6129"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 347us/step - loss: 1.0855 - acc: 0.6142 - val_loss: 1.0090 - val_acc: 0.6449\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 17s 346us/step - loss: 1.0391 - acc: 0.6311 - val_loss: 0.9533 - val_acc: 0.6633\n",
            "Epoch 11/20\n",
            "35200/50000 [====================>.........] - ETA: 4s - loss: 1.0171 - acc: 0.6399"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 349us/step - loss: 1.0084 - acc: 0.6418 - val_loss: 0.9583 - val_acc: 0.6641\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 18s 350us/step - loss: 0.9709 - acc: 0.6527 - val_loss: 0.9303 - val_acc: 0.6743\n",
            "Epoch 13/20\n",
            "35328/50000 [====================>.........] - ETA: 4s - loss: 0.9443 - acc: 0.6664"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 348us/step - loss: 0.9379 - acc: 0.6685 - val_loss: 0.8368 - val_acc: 0.7038\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 17s 348us/step - loss: 0.9104 - acc: 0.6773 - val_loss: 0.8408 - val_acc: 0.7045\n",
            "Epoch 15/20\n",
            "35328/50000 [====================>.........] - ETA: 4s - loss: 0.8859 - acc: 0.6864"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 348us/step - loss: 0.8841 - acc: 0.6877 - val_loss: 0.8950 - val_acc: 0.6890\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 17s 349us/step - loss: 0.8611 - acc: 0.6959 - val_loss: 0.8247 - val_acc: 0.7083\n",
            "Epoch 17/20\n",
            "34944/50000 [===================>..........] - ETA: 4s - loss: 0.8429 - acc: 0.7023"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 350us/step - loss: 0.8404 - acc: 0.7033 - val_loss: 0.8125 - val_acc: 0.7171\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 18s 353us/step - loss: 0.8185 - acc: 0.7116 - val_loss: 0.7633 - val_acc: 0.7341\n",
            "Epoch 19/20\n",
            "34816/50000 [===================>..........] - ETA: 4s - loss: 0.8042 - acc: 0.7191"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 347us/step - loss: 0.8051 - acc: 0.7177 - val_loss: 0.7561 - val_acc: 0.7373\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 17s 346us/step - loss: 0.7813 - acc: 0.7225 - val_loss: 0.7757 - val_acc: 0.7313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L-1gJhvUuWMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7b9d437d-8685-409b-9405-6deb634c43f9"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = keras.models.load_model('cifra10_batch.h5')\n",
        "print('\\n  - Model with Batch Normalization:')\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('\\tTest loss:\\t', scores[0])\n",
        "print('\\tTest accuracy:\\t', scores[1])\n",
        "\n",
        "Y_pred = model.predict(x_test, verbose=2)\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(Y_pred, axis=1))\n",
        "print('\\tConfusion Matrix:\\t')\n",
        "print(cm)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  - Model with Batch Normalization:\n",
            "\tTest loss:\t 0.7756728023529053\n",
            "\tTest accuracy:\t 0.7313\n",
            "\tConfusion Matrix:\t\n",
            "[[740  11  72  13  44   6  18  24  51  21]\n",
            " [ 20 831   8  15   6   5  24   4  25  62]\n",
            " [ 46   1 580  34 151  52 104  21   7   4]\n",
            " [  8   3  57 451 111 181 150  29   8   2]\n",
            " [  7   2  28  25 817  12  75  30   4   0]\n",
            " [  5   0  48 147  96 625  42  33   3   1]\n",
            " [  3   0  26  30  38   5 893   1   4   0]\n",
            " [  8   1  37  18 104  49  16 766   0   1]\n",
            " [ 54  25  16  13  13   5  10   2 847  15]\n",
            " [ 37  59  10  21  21  12  19  23  35 763]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MmxET6jumTsx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Second model: regularizer"
      ]
    },
    {
      "metadata": {
        "id": "ptxx_FTouWMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "7d9e761a-59c6-4d3a-9cd0-1a079731b1de"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import regularizers\n",
        "\n",
        "weight_decay = 1e-4\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            shuffle=True)\n",
        "\n",
        "model.save('cifra10_regL2.h5')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 14s 275us/step - loss: 2.0026 - acc: 0.2676 - val_loss: 1.7278 - val_acc: 0.3963\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 13s 259us/step - loss: 1.6662 - acc: 0.3998 - val_loss: 1.5401 - val_acc: 0.4575\n",
            "Epoch 3/20\n",
            " 9088/50000 [====>.........................] - ETA: 10s - loss: 1.5727 - acc: 0.4316"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 259us/step - loss: 1.5268 - acc: 0.4512 - val_loss: 1.4088 - val_acc: 0.5077\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 13s 259us/step - loss: 1.4438 - acc: 0.4832 - val_loss: 1.3500 - val_acc: 0.5263\n",
            "Epoch 5/20\n",
            "30336/50000 [=================>............] - ETA: 4s - loss: 1.3816 - acc: 0.5116"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 257us/step - loss: 1.3747 - acc: 0.5148 - val_loss: 1.3097 - val_acc: 0.5400\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 13s 258us/step - loss: 1.3191 - acc: 0.5339 - val_loss: 1.2477 - val_acc: 0.5655\n",
            "Epoch 7/20\n",
            "35200/50000 [====================>.........] - ETA: 3s - loss: 1.2760 - acc: 0.5480"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 258us/step - loss: 1.2718 - acc: 0.5510 - val_loss: 1.2217 - val_acc: 0.5723\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 13s 258us/step - loss: 1.2327 - acc: 0.5660 - val_loss: 1.1381 - val_acc: 0.6027\n",
            "Epoch 9/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.1917 - acc: 0.5830"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 258us/step - loss: 1.1918 - acc: 0.5829 - val_loss: 1.1052 - val_acc: 0.6133\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 13s 258us/step - loss: 1.1593 - acc: 0.5966 - val_loss: 1.0729 - val_acc: 0.6277\n",
            "Epoch 11/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.1264 - acc: 0.6065"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 259us/step - loss: 1.1288 - acc: 0.6060 - val_loss: 1.0311 - val_acc: 0.6444\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 13s 258us/step - loss: 1.1016 - acc: 0.6201 - val_loss: 1.0441 - val_acc: 0.6390\n",
            "Epoch 13/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.0792 - acc: 0.6260"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 259us/step - loss: 1.0747 - acc: 0.6284 - val_loss: 1.0279 - val_acc: 0.6469\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 13s 258us/step - loss: 1.0455 - acc: 0.6400 - val_loss: 0.9752 - val_acc: 0.6595\n",
            "Epoch 15/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.0287 - acc: 0.6452"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 258us/step - loss: 1.0280 - acc: 0.6440 - val_loss: 0.9799 - val_acc: 0.6637\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 13s 260us/step - loss: 1.0059 - acc: 0.6528 - val_loss: 0.9497 - val_acc: 0.6720\n",
            "Epoch 17/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 0.9830 - acc: 0.6628"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 258us/step - loss: 0.9849 - acc: 0.6614 - val_loss: 0.9357 - val_acc: 0.6794\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 0.9631 - acc: 0.6662 - val_loss: 0.9027 - val_acc: 0.6903\n",
            "Epoch 19/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 0.9423 - acc: 0.6759"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 257us/step - loss: 0.9482 - acc: 0.6738 - val_loss: 0.9219 - val_acc: 0.6837\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 0.9312 - acc: 0.6795 - val_loss: 0.8839 - val_acc: 0.7000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kdaY9vZpuWMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "458a476f-42e8-4ad8-d86b-edb5e8ea60aa"
      },
      "cell_type": "code",
      "source": [
        "model= keras.models.load_model('cifra10_regL2.h5')\n",
        "print('\\n  - regularizer L2:')\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('\\tTest loss:\\t', scores[0])\n",
        "print('\\tTest accuracy:\\t', scores[1])\n",
        "\n",
        "Y_pred = model.predict(x_test, verbose=2)\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(Y_pred, axis=1))\n",
        "print('\\tConfusion Matrix:\\t')\n",
        "print(cm)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  - regularizer L2:\n",
            "\tTest loss:\t 0.8838677503585816\n",
            "\tTest accuracy:\t 0.7\n",
            "\tConfusion Matrix:\t\n",
            "[[714  26  41  25  17   5  15   9 103  45]\n",
            " [ 15 858   5  12   4   3  15   3  34  51]\n",
            " [ 65   8 535  72 112  67  90  25  14  12]\n",
            " [ 15   9  63 525  85 134 113  21  22  13]\n",
            " [ 22   4  52  53 656  21 108  61  17   6]\n",
            " [  5   4  57 201  57 552  61  47   8   8]\n",
            " [  4   3  33  43  33  10 855   5   8   6]\n",
            " [ 13   5  28  47  83  60  14 731   4  15]\n",
            " [ 48  33  10  15   6   8   9   3 845  23]\n",
            " [ 24 123   6  20   8   4  26  15  45 729]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XRymftMOmTs3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3) Try another method for dealing with overfitting"
      ]
    },
    {
      "metadata": {
        "id": "S7i58d-1uWMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "fa5153f1-ca0f-4fbc-f909-4a45d822176b"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import regularizers\n",
        "\n",
        "weight_decay = 1e-4\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            shuffle=True)\n",
        "\n",
        "model.save('cifra10_batch_regL2.h5')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 19s 382us/step - loss: 1.9461 - acc: 0.3075 - val_loss: 1.5003 - val_acc: 0.4614\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 18s 353us/step - loss: 1.5682 - acc: 0.4320 - val_loss: 1.3441 - val_acc: 0.5149\n",
            "Epoch 3/20\n",
            " 8576/50000 [====>.........................] - ETA: 13s - loss: 1.4778 - acc: 0.4641"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 352us/step - loss: 1.4408 - acc: 0.4829 - val_loss: 1.2821 - val_acc: 0.5479\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 18s 351us/step - loss: 1.3558 - acc: 0.5142 - val_loss: 1.2352 - val_acc: 0.5592\n",
            "Epoch 5/20\n",
            "29568/50000 [================>.............] - ETA: 6s - loss: 1.3038 - acc: 0.5343"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 349us/step - loss: 1.2937 - acc: 0.5404 - val_loss: 1.1946 - val_acc: 0.5763\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 17s 349us/step - loss: 1.2304 - acc: 0.5645 - val_loss: 1.1992 - val_acc: 0.5793\n",
            "Epoch 7/20\n",
            "34176/50000 [===================>..........] - ETA: 5s - loss: 1.1837 - acc: 0.5805"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 353us/step - loss: 1.1752 - acc: 0.5842 - val_loss: 1.2086 - val_acc: 0.5912\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 18s 353us/step - loss: 1.1254 - acc: 0.6012 - val_loss: 1.0499 - val_acc: 0.6297\n",
            "Epoch 9/20\n",
            "35200/50000 [====================>.........] - ETA: 4s - loss: 1.0827 - acc: 0.6187"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 353us/step - loss: 1.0783 - acc: 0.6195 - val_loss: 1.0191 - val_acc: 0.6432\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 18s 351us/step - loss: 1.0366 - acc: 0.6337 - val_loss: 0.9444 - val_acc: 0.6732\n",
            "Epoch 11/20\n",
            "35456/50000 [====================>.........] - ETA: 4s - loss: 1.0022 - acc: 0.6470"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 349us/step - loss: 0.9998 - acc: 0.6481 - val_loss: 1.0510 - val_acc: 0.6407\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 18s 350us/step - loss: 0.9666 - acc: 0.6589 - val_loss: 0.9194 - val_acc: 0.6855\n",
            "Epoch 13/20\n",
            "35200/50000 [====================>.........] - ETA: 4s - loss: 0.9411 - acc: 0.6696"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 352us/step - loss: 0.9360 - acc: 0.6712 - val_loss: 0.8710 - val_acc: 0.6987\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 18s 352us/step - loss: 0.9062 - acc: 0.6800 - val_loss: 0.8972 - val_acc: 0.6928\n",
            "Epoch 15/20\n",
            "35328/50000 [====================>.........] - ETA: 4s - loss: 0.8896 - acc: 0.6912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 350us/step - loss: 0.8848 - acc: 0.6910 - val_loss: 0.8401 - val_acc: 0.7159\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 17s 350us/step - loss: 0.8595 - acc: 0.6967 - val_loss: 0.7957 - val_acc: 0.7279\n",
            "Epoch 17/20\n",
            "35328/50000 [====================>.........] - ETA: 4s - loss: 0.8423 - acc: 0.7068"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 350us/step - loss: 0.8408 - acc: 0.7069 - val_loss: 0.8260 - val_acc: 0.7163\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 18s 352us/step - loss: 0.8191 - acc: 0.7123 - val_loss: 0.8365 - val_acc: 0.7121\n",
            "Epoch 19/20\n",
            "35712/50000 [====================>.........] - ETA: 4s - loss: 0.8014 - acc: 0.7203"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 351us/step - loss: 0.8008 - acc: 0.7206 - val_loss: 0.7795 - val_acc: 0.7325\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 18s 351us/step - loss: 0.7840 - acc: 0.7275 - val_loss: 0.8523 - val_acc: 0.7121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jpd39SHkuWMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7846c318-d1e4-4c98-d0b1-68d2ac078ce9"
      },
      "cell_type": "code",
      "source": [
        "model.save('cifra10_batch_regL2.h5')\n",
        "print('\\n  - Model with batch normalization and regularizer:')\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('\\tTest loss:\\t', scores[0])\n",
        "print('\\tTest accuracy:\\t', scores[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  - Model with batch normalization and regularizer:\n",
            "\tTest loss:\t 0.8522795192718506\n",
            "\tTest accuracy:\t 0.7121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mxwsz6ZUuWMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "8994f636-0145-40cb-f628-3eeb062b58a7"
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('cifra10_batch.h5')\n",
        "model.add(keras.layers.GaussianNoise(0.01))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            shuffle=True)\n",
        "model.save('cifra10_batch_n0.01.h5')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 19s 375us/step - loss: 0.8210 - acc: 0.7247 - val_loss: 0.7723 - val_acc: 0.7325\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 18s 352us/step - loss: 0.8101 - acc: 0.7312 - val_loss: 0.7703 - val_acc: 0.7334\n",
            "Epoch 3/20\n",
            " 8576/50000 [====>.........................] - ETA: 13s - loss: 0.8019 - acc: 0.7367"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 354us/step - loss: 0.7963 - acc: 0.7351 - val_loss: 0.7874 - val_acc: 0.7294\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 18s 351us/step - loss: 0.7837 - acc: 0.7387 - val_loss: 0.7038 - val_acc: 0.7566\n",
            "Epoch 5/20\n",
            "29568/50000 [================>.............] - ETA: 6s - loss: 0.7724 - acc: 0.7468"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 351us/step - loss: 0.7750 - acc: 0.7446 - val_loss: 0.7488 - val_acc: 0.7422\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 17s 348us/step - loss: 0.7707 - acc: 0.7467 - val_loss: 0.7184 - val_acc: 0.7510\n",
            "Epoch 7/20\n",
            "34688/50000 [===================>..........] - ETA: 5s - loss: 0.7457 - acc: 0.7525"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 350us/step - loss: 0.7496 - acc: 0.7520 - val_loss: 0.8515 - val_acc: 0.7062\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 18s 353us/step - loss: 0.7456 - acc: 0.7530 - val_loss: 0.7395 - val_acc: 0.7487\n",
            "Epoch 9/20\n",
            "35328/50000 [====================>.........] - ETA: 4s - loss: 0.7339 - acc: 0.7557"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 352us/step - loss: 0.7329 - acc: 0.7565 - val_loss: 0.7490 - val_acc: 0.7435\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 18s 352us/step - loss: 0.7259 - acc: 0.7621 - val_loss: 0.6818 - val_acc: 0.7642\n",
            "Epoch 11/20\n",
            "34944/50000 [===================>..........] - ETA: 4s - loss: 0.7129 - acc: 0.7618"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 349us/step - loss: 0.7176 - acc: 0.7622 - val_loss: 0.6787 - val_acc: 0.7663\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 18s 352us/step - loss: 0.7034 - acc: 0.7679 - val_loss: 0.7400 - val_acc: 0.7453\n",
            "Epoch 13/20\n",
            "35328/50000 [====================>.........] - ETA: 4s - loss: 0.6931 - acc: 0.7717"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 351us/step - loss: 0.7027 - acc: 0.7711 - val_loss: 0.7097 - val_acc: 0.7578\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 18s 354us/step - loss: 0.6790 - acc: 0.7745 - val_loss: 0.6537 - val_acc: 0.7727\n",
            "Epoch 15/20\n",
            "35072/50000 [====================>.........] - ETA: 4s - loss: 0.6829 - acc: 0.7755"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 353us/step - loss: 0.6843 - acc: 0.7749 - val_loss: 0.7396 - val_acc: 0.7472\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 17s 349us/step - loss: 0.6828 - acc: 0.7742 - val_loss: 0.6643 - val_acc: 0.7729\n",
            "Epoch 17/20\n",
            "34816/50000 [===================>..........] - ETA: 4s - loss: 0.6569 - acc: 0.7845"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 350us/step - loss: 0.6659 - acc: 0.7816 - val_loss: 0.6720 - val_acc: 0.7682\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 17s 349us/step - loss: 0.6553 - acc: 0.7839 - val_loss: 0.6703 - val_acc: 0.7711\n",
            "Epoch 19/20\n",
            "35072/50000 [====================>.........] - ETA: 4s - loss: 0.6517 - acc: 0.7834"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 352us/step - loss: 0.6529 - acc: 0.7834 - val_loss: 0.6836 - val_acc: 0.7681\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 18s 351us/step - loss: 0.6535 - acc: 0.7891 - val_loss: 0.6446 - val_acc: 0.7755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gmCzNoVQuWMl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "518e97b8-d634-4959-e77f-44024849efe5"
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('cifra10_batch_n0.01.h5')\n",
        "\n",
        "print('\\n  - Model with Batch Normalization and Gaussian Noise with 0.01 stdev:')\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('\\tTest loss:\\t', scores[0])\n",
        "print('\\tTest accuracy:\\t', scores[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  - Model with Batch Normalization and Gaussian Noise with 0.01 stdev:\n",
            "\tTest loss:\t 0.6446445227622986\n",
            "\tTest accuracy:\t 0.7755\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}