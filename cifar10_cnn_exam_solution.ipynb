{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/timohe/ML-Keras_ConvNeuralNet/blob/master/cifar10_cnn_exam_solution.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwL1HaHTuWLt"
   },
   "source": [
    "# CIFAR10 with CNN\n",
    "code from https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "tkM8NCnJuWLv"
   },
   "source": [
    "This notebook trains a simple convolutional neural network on the CIFAR10 small images dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8UZFSsBuWLv"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "#for confusion matrix\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HX32-SrFuWL0"
   },
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "o07n3FvbuWL0",
    "outputId": "0b4f95b9-d8e8-4c6d-ca02-51b5661c0d1b"
   },
   "outputs": [],
   "source": [
    "# define constants\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Cast features into correct data type then scale features\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cW5LnHj5uWL3"
   },
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYl_mjtUuWL4"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MSNoYmMFuWL5"
   },
   "source": [
    "Show model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "CF1UH3FsuWL6",
    "outputId": "b9f428eb-6074-4d14-c959-5fb0efcbc00c"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5LrNtCcXuWL9"
   },
   "source": [
    "Compile model and fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "j--3W_mEuWL9",
    "outputId": "6e5f79d0-63f3-41f6-8c65-58de8ccdc428"
   },
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "colab_type": "code",
    "id": "TnqygMfpuWMF",
    "outputId": "f1b5fdd0-daa6-454d-cefe-cf9dfa07c140"
   },
   "outputs": [],
   "source": [
    "# Save the original model\n",
    "model.save('savedFiles/cifra10_base.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjAnVrbjuWMH",
    "outputId": "2a5cb27d-7411-456c-bb63-743db136b0cf"
   },
   "outputs": [],
   "source": [
    "# Print base model loss and accuracy\n",
    "print('\\n  - Base case:')\n",
    "model = keras.models.load_model(\"savedFiles/cifra10_base.h5\")\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\tTest loss:\\t', scores[0])\n",
    "print('\\tTest accuracy:\\t', scores[1])\n",
    "Y_pred = model.predict(x_test, verbose=2)\n",
    "cm = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(Y_pred, axis=1))\n",
    "print('\\tConfusion Matrix:\\t')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Augment the data by adding noise. Discuss results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMBbUhcTuWMJ"
   },
   "outputs": [],
   "source": [
    "# Save models with gaussian noise with different Standard Deviation\n",
    "for e in [0.08,0.07,0.06,0.05,0.04,0.03,0.02,0.01]:\n",
    "    model = keras.models.load_model(\"savedFiles/cifra10_base.h5\")\n",
    "    model.add(keras.layers.GaussianNoise(e))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                    metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=(x_test, y_test),\n",
    "                shuffle=True)\n",
    "    model.save('savedFiles/cifra10_n'+str(e)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVUkk-43uWML",
    "outputId": "16ffc791-4cdb-4807-f146-fda87da35735"
   },
   "outputs": [],
   "source": [
    "# Load models and print results\n",
    "for e in [0.08,0.07,0.06,0.05,0.04,0.03,0.02,0.01]:\n",
    "    model = keras.models.load_model('savedFiles/cifra10_n'+str(e)+'.h5')\n",
    "    print('\\n  - Gaussian Noise with '+str(e)+' stdev:')\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('\\tTest loss:\\t', scores[0])\n",
    "    print('\\tTest accuracy:\\t', scores[1])\n",
    "    \n",
    "# Load and print of the best loss and accuracy obtained\n",
    "model = keras.models.load_model(\"savedFiles/cifra10_n0.02.h5\")\n",
    "print('\\n\\nBest results:')\n",
    "print('  - Gaussian Noise with 0.02 stdev:')\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\tTest loss:\\t', scores[0])\n",
    "print('\\tTest accuracy:\\t', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Add layers to the network to see if can improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First model: batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2KL0hWjuWMO",
    "outputId": "aa6b71ff-683b-4a8b-cd83-f24267e65083"
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=True)\n",
    "\n",
    "model.save('savedFiles/cifra10_batch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "L-1gJhvUuWMR",
    "outputId": "c089cfa8-2cea-4965-99dd-cf8be1f52887"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = keras.models.load_model('savedFiles/cifra10_batch.h5')\n",
    "print('\\n  - Model with Batch Normalization:')\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\tTest loss:\\t', scores[0])\n",
    "print('\\tTest accuracy:\\t', scores[1])\n",
    "\n",
    "Y_pred = model.predict(x_test, verbose=2)\n",
    "cm = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(Y_pred, axis=1))\n",
    "print('\\tConfusion Matrix:\\t')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second model: regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ptxx_FTouWMU",
    "outputId": "1cf79319-6518-49f5-fc53-de4dd44b53c1"
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=True)\n",
    "\n",
    "model.save('savedFiles/cifra10_regL2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdaY9vZpuWMa",
    "outputId": "c7f35df9-13b8-435a-e0cd-10bff7cca467"
   },
   "outputs": [],
   "source": [
    "model= keras.models.load_model('savedFiles/cifra10_regL2.h5')\n",
    "print('\\n  - regularizer L2:')\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\tTest loss:\\t', scores[0])\n",
    "print('\\tTest accuracy:\\t', scores[1])\n",
    "\n",
    "Y_pred = model.predict(x_test, verbose=2)\n",
    "cm = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(Y_pred, axis=1))\n",
    "print('\\tConfusion Matrix:\\t')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Try another method for dealing with overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S7i58d-1uWMc",
    "outputId": "a1508d27-3c63-4708-e9ac-3cbebe0d5016"
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=True)\n",
    "\n",
    "model.save('savedFiles/cifra10_batch_regL2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpd39SHkuWMf",
    "outputId": "c959bbd6-401b-47e0-e29d-7f4b71f7952a"
   },
   "outputs": [],
   "source": [
    "model.save('savedFiles/cifra10_batch_regL2.h5')\n",
    "print('\\n  - Model with batch normalization and regularizer:')\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\tTest loss:\\t', scores[0])\n",
    "print('\\tTest accuracy:\\t', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxwsz6ZUuWMh",
    "outputId": "98431b86-99dc-4f95-d231-9e832d28d69f"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('savedFiles/cifra10_batch.h5')\n",
    "model.add(keras.layers.GaussianNoise(0.01))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=True)\n",
    "model.save('savedFiles/cifra10_batch_n0.01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmCzNoVQuWMl",
    "outputId": "33348eab-6587-4ab2-cd6a-398686db25ba"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('savedFiles/cifra10_batch_n0.01.h5')\n",
    "\n",
    "print('\\n  - Model with Batch Normalization and Gaussian Noise with 0.01 stdev:')\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\tTest loss:\\t', scores[0])\n",
    "print('\\tTest accuracy:\\t', scores[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cifar10_cnn_exam solution.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
