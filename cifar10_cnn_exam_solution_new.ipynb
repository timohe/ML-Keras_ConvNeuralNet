{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_cnn_exam_solution.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "CwL1HaHTuWLt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CIFAR10 with CNN\n",
        "code from https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n"
      ]
    },
    {
      "metadata": {
        "id": "tkM8NCnJuWLv",
        "colab_type": "raw"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook trains a simple convolutional neural network on the CIFAR10 small images dataset. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "S8UZFSsBuWLv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7913b09c-a4a2-467d-a0eb-67d36f51f6dd"
      },
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from __future__ import print_function\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "#for confusion matrix\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HX32-SrFuWL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prepare data"
      ]
    },
    {
      "metadata": {
        "id": "o07n3FvbuWL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4154418a-5281-4a5d-b883-a95202f386b3"
      },
      "cell_type": "code",
      "source": [
        "# define constants\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "# The data, shuffled and split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Cast features into correct data type then scale features\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cW5LnHj5uWL3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define model"
      ]
    },
    {
      "metadata": {
        "id": "YYl_mjtUuWL4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MSNoYmMFuWL5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Show model structure"
      ]
    },
    {
      "metadata": {
        "id": "CF1UH3FsuWL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "6b79077a-e098-4eb4-9721-c184434fedde"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5LrNtCcXuWL9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compile model and fit\n"
      ]
    },
    {
      "metadata": {
        "id": "j--3W_mEuWL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "1be9071b-a851-406e-d795-2fb152baf7f9"
      },
      "cell_type": "code",
      "source": [
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            shuffle=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 15s 299us/step - loss: 1.9890 - acc: 0.2733 - val_loss: 1.7458 - val_acc: 0.3773\n",
            "Epoch 2/20\n",
            "20352/50000 [===========>..................] - ETA: 7s - loss: 1.7569 - acc: 0.3632"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.7134 - acc: 0.3822 - val_loss: 1.6298 - val_acc: 0.4109\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 1.5972 - acc: 0.4225 - val_loss: 1.4859 - val_acc: 0.4644\n",
            "Epoch 4/20\n",
            "32896/50000 [==================>...........] - ETA: 4s - loss: 1.5245 - acc: 0.4516"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.5088 - acc: 0.4570 - val_loss: 1.4500 - val_acc: 0.4727\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.4302 - acc: 0.4870 - val_loss: 1.3356 - val_acc: 0.5233\n",
            "Epoch 6/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.3735 - acc: 0.5112"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 253us/step - loss: 1.3679 - acc: 0.5132 - val_loss: 1.2703 - val_acc: 0.5476\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 1.3145 - acc: 0.5327 - val_loss: 1.2423 - val_acc: 0.5589\n",
            "Epoch 8/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.2674 - acc: 0.5497"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 253us/step - loss: 1.2645 - acc: 0.5515 - val_loss: 1.1815 - val_acc: 0.5799\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 1.2235 - acc: 0.5687 - val_loss: 1.1433 - val_acc: 0.5965\n",
            "Epoch 10/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.1860 - acc: 0.5810"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.1812 - acc: 0.5829 - val_loss: 1.1258 - val_acc: 0.6011\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 1.1374 - acc: 0.5997 - val_loss: 1.0812 - val_acc: 0.6212\n",
            "Epoch 12/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.1078 - acc: 0.6099"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 253us/step - loss: 1.1059 - acc: 0.6103 - val_loss: 1.0586 - val_acc: 0.6285\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 1.0775 - acc: 0.6211 - val_loss: 0.9928 - val_acc: 0.6549\n",
            "Epoch 14/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.0466 - acc: 0.6333"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.0467 - acc: 0.6323 - val_loss: 0.9848 - val_acc: 0.6521\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.0175 - acc: 0.6450 - val_loss: 0.9890 - val_acc: 0.6575\n",
            "Epoch 16/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 0.9988 - acc: 0.6508"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 254us/step - loss: 0.9960 - acc: 0.6523 - val_loss: 0.9409 - val_acc: 0.6770\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 0.9719 - acc: 0.6592 - val_loss: 0.9596 - val_acc: 0.6677\n",
            "Epoch 18/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 0.9559 - acc: 0.6655"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 255us/step - loss: 0.9530 - acc: 0.6654 - val_loss: 0.9257 - val_acc: 0.6759\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 0.9354 - acc: 0.6736 - val_loss: 0.8829 - val_acc: 0.6941\n",
            "Epoch 20/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 0.9161 - acc: 0.6794"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 254us/step - loss: 0.9138 - acc: 0.6806 - val_loss: 0.8781 - val_acc: 0.6973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8be6958f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "TnqygMfpuWMF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save the original model\n",
        "model.save('cifra10_base.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qjAnVrbjuWMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "8128ccfa-289f-483b-a2ce-d26c515b3704"
      },
      "cell_type": "code",
      "source": [
        "# Print base model loss and accuracy\n",
        "print('\\n  - Base case:')\n",
        "model = keras.models.load_model(\"cifra10_base.h5\")\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('\\tTest loss:\\t', scores[0])\n",
        "print('\\tTest accuracy:\\t', scores[1])\n",
        "Y_pred = model.predict(x_test, verbose=2)\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(Y_pred, axis=1))\n",
        "print('\\tConfusion Matrix:\\t')\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  - Base case:\n",
            "\tTest loss:\t 0.8781241746902466\n",
            "\tTest accuracy:\t 0.6973\n",
            "\tConfusion Matrix:\t\n",
            "[[733  29  39  18  24   6  10  12  56  73]\n",
            " [  4 841   2   4   4   1   8   4  10 122]\n",
            " [ 72   8 470  61 165  65  69  55  14  21]\n",
            " [ 19  13  51 468 121 147  68  60  14  39]\n",
            " [ 21   5  29  44 723  14  47  97  14   6]\n",
            " [  9  11  35 179  77 564  27  77   6  15]\n",
            " [  8   4  25  54  71  17 784  13   5  19]\n",
            " [ 10   5  18  23  85  46   5 781   2  25]\n",
            " [ 65  66  11  13   6   5   5   5 769  55]\n",
            " [ 16  77   4  10   8   3   6  18  18 840]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yt0xEddBmTsk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1) Augment the data by adding noise."
      ]
    },
    {
      "metadata": {
        "id": "AMBbUhcTuWMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3522
        },
        "outputId": "d279bce9-3a01-4166-9261-5ef8e518d9c7"
      },
      "cell_type": "code",
      "source": [
        "# Save models with gaussian noise with different Standard Deviation\n",
        "for e in [0.5,0.1,0.05,0.02,0.01]:  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  #Add noise\n",
        "  model.add(keras.layers.GaussianNoise(e))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  model.fit(x_train, y_train,\n",
        "                batch_size=batch_size,\n",
        "                epochs=epochs,\n",
        "                validation_data=(x_test, y_test),\n",
        "                shuffle=True)\n",
        "  model.save('cifra10_n'+str(e)+'.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 15s 298us/step - loss: 2.2585 - acc: 0.1440 - val_loss: 2.3808 - val_acc: 0.0999\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.0537 - acc: 0.2404 - val_loss: 2.2931 - val_acc: 0.1495\n",
            "Epoch 3/20\n",
            " 8832/50000 [====>.........................] - ETA: 10s - loss: 1.9837 - acc: 0.2656"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.9297 - acc: 0.2915 - val_loss: 2.1901 - val_acc: 0.1795\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.7963 - acc: 0.3441 - val_loss: 1.9360 - val_acc: 0.2904\n",
            "Epoch 5/20\n",
            "29312/50000 [================>.............] - ETA: 5s - loss: 1.7338 - acc: 0.3667"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.7223 - acc: 0.3717 - val_loss: 1.8513 - val_acc: 0.3286\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.6664 - acc: 0.3942 - val_loss: 1.8158 - val_acc: 0.3490\n",
            "Epoch 7/20\n",
            "34432/50000 [===================>..........] - ETA: 3s - loss: 1.6228 - acc: 0.4115"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 260us/step - loss: 1.6195 - acc: 0.4130 - val_loss: 1.7803 - val_acc: 0.3685\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 13s 259us/step - loss: 1.5787 - acc: 0.4292 - val_loss: 1.7900 - val_acc: 0.3656\n",
            "Epoch 9/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.5473 - acc: 0.4395"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.5413 - acc: 0.4422 - val_loss: 1.6679 - val_acc: 0.3968\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.5066 - acc: 0.4574 - val_loss: 1.5884 - val_acc: 0.4230\n",
            "Epoch 11/20\n",
            "35456/50000 [====================>.........] - ETA: 3s - loss: 1.4842 - acc: 0.4645"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.4765 - acc: 0.4678 - val_loss: 1.7051 - val_acc: 0.3825\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.4497 - acc: 0.4783 - val_loss: 1.7000 - val_acc: 0.3975\n",
            "Epoch 13/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.4305 - acc: 0.4827"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.4258 - acc: 0.4848 - val_loss: 1.5844 - val_acc: 0.4291\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.4039 - acc: 0.4938 - val_loss: 1.5303 - val_acc: 0.4393\n",
            "Epoch 15/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.3769 - acc: 0.5043"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 258us/step - loss: 1.3782 - acc: 0.5054 - val_loss: 1.4810 - val_acc: 0.4615\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.3575 - acc: 0.5131 - val_loss: 1.4541 - val_acc: 0.4748\n",
            "Epoch 17/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.3374 - acc: 0.5210"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.3394 - acc: 0.5205 - val_loss: 1.4336 - val_acc: 0.4795\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.3182 - acc: 0.5271 - val_loss: 1.4159 - val_acc: 0.4942\n",
            "Epoch 19/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.2964 - acc: 0.5377"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.2981 - acc: 0.5364 - val_loss: 1.3978 - val_acc: 0.4985\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.2773 - acc: 0.5444 - val_loss: 1.3756 - val_acc: 0.5045\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "31104/50000 [=================>............] - ETA: 5s - loss: 2.1460 - acc: 0.1986"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 15s 301us/step - loss: 2.0767 - acc: 0.2306 - val_loss: 1.9235 - val_acc: 0.3143\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.7851 - acc: 0.3558 - val_loss: 1.6556 - val_acc: 0.4164\n",
            "Epoch 3/20\n",
            "35200/50000 [====================>.........] - ETA: 3s - loss: 1.6732 - acc: 0.3990"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 260us/step - loss: 1.6659 - acc: 0.4003 - val_loss: 1.5888 - val_acc: 0.4323\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.5835 - acc: 0.4303 - val_loss: 1.5012 - val_acc: 0.4575\n",
            "Epoch 5/20\n",
            "35200/50000 [====================>.........] - ETA: 3s - loss: 1.5285 - acc: 0.4482"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.5168 - acc: 0.4532 - val_loss: 1.4187 - val_acc: 0.4949\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.4595 - acc: 0.4747 - val_loss: 1.4406 - val_acc: 0.4808\n",
            "Epoch 7/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.4110 - acc: 0.4921"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.4063 - acc: 0.4937 - val_loss: 1.3867 - val_acc: 0.4977\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.3699 - acc: 0.5096 - val_loss: 1.2803 - val_acc: 0.5449\n",
            "Epoch 9/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.3276 - acc: 0.5249"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.3230 - acc: 0.5277 - val_loss: 1.2625 - val_acc: 0.5462\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.2944 - acc: 0.5398 - val_loss: 1.2345 - val_acc: 0.5572\n",
            "Epoch 11/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.2660 - acc: 0.5492"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 260us/step - loss: 1.2637 - acc: 0.5503 - val_loss: 1.2082 - val_acc: 0.5671\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.2347 - acc: 0.5632 - val_loss: 1.1756 - val_acc: 0.5793\n",
            "Epoch 13/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.2191 - acc: 0.5654"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.2124 - acc: 0.5677 - val_loss: 1.1193 - val_acc: 0.6049\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.1824 - acc: 0.5797 - val_loss: 1.0899 - val_acc: 0.6140\n",
            "Epoch 15/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.1589 - acc: 0.5905"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.1557 - acc: 0.5917 - val_loss: 1.1024 - val_acc: 0.6096\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.1363 - acc: 0.5995 - val_loss: 1.0645 - val_acc: 0.6271\n",
            "Epoch 17/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.1159 - acc: 0.6063"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.1136 - acc: 0.6074 - val_loss: 1.0963 - val_acc: 0.6114\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.0979 - acc: 0.6141 - val_loss: 1.0753 - val_acc: 0.6263\n",
            "Epoch 19/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.0801 - acc: 0.6193"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.0759 - acc: 0.6212 - val_loss: 1.0057 - val_acc: 0.6487\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.0588 - acc: 0.6279 - val_loss: 0.9894 - val_acc: 0.6573\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "31360/50000 [=================>............] - ETA: 5s - loss: 2.1301 - acc: 0.2063"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 15s 303us/step - loss: 2.0441 - acc: 0.2461 - val_loss: 1.8145 - val_acc: 0.3689\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.7419 - acc: 0.3690 - val_loss: 1.6482 - val_acc: 0.4124\n",
            "Epoch 3/20\n",
            "35456/50000 [====================>.........] - ETA: 3s - loss: 1.6337 - acc: 0.4053"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.6198 - acc: 0.4121 - val_loss: 1.5069 - val_acc: 0.4642\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.5349 - acc: 0.4445 - val_loss: 1.4342 - val_acc: 0.4802\n",
            "Epoch 5/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.4690 - acc: 0.4705"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.4611 - acc: 0.4742 - val_loss: 1.3794 - val_acc: 0.5051\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.4071 - acc: 0.4959 - val_loss: 1.3646 - val_acc: 0.5094\n",
            "Epoch 7/20\n",
            "35200/50000 [====================>.........] - ETA: 3s - loss: 1.3699 - acc: 0.5141"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.3605 - acc: 0.5159 - val_loss: 1.3075 - val_acc: 0.5356\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.3212 - acc: 0.5315 - val_loss: 1.3054 - val_acc: 0.5318\n",
            "Epoch 9/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.2821 - acc: 0.5446"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.2824 - acc: 0.5446 - val_loss: 1.2381 - val_acc: 0.5597\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.2537 - acc: 0.5577 - val_loss: 1.2117 - val_acc: 0.5754\n",
            "Epoch 11/20\n",
            "35456/50000 [====================>.........] - ETA: 3s - loss: 1.2239 - acc: 0.5642"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.2204 - acc: 0.5668 - val_loss: 1.1975 - val_acc: 0.5822\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.1958 - acc: 0.5785 - val_loss: 1.1180 - val_acc: 0.6095\n",
            "Epoch 13/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.1622 - acc: 0.5897"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.1617 - acc: 0.5898 - val_loss: 1.1155 - val_acc: 0.6102\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 1.1369 - acc: 0.6013 - val_loss: 1.0672 - val_acc: 0.6308\n",
            "Epoch 15/20\n",
            "35456/50000 [====================>.........] - ETA: 3s - loss: 1.1196 - acc: 0.6065"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.1146 - acc: 0.6088 - val_loss: 1.0875 - val_acc: 0.6243\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.0902 - acc: 0.6185 - val_loss: 1.0277 - val_acc: 0.6444\n",
            "Epoch 17/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.0642 - acc: 0.6261"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.0646 - acc: 0.6264 - val_loss: 1.0024 - val_acc: 0.6535\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.0515 - acc: 0.6304 - val_loss: 0.9826 - val_acc: 0.6552\n",
            "Epoch 19/20\n",
            "35456/50000 [====================>.........] - ETA: 3s - loss: 1.0279 - acc: 0.6402"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 264us/step - loss: 1.0296 - acc: 0.6400 - val_loss: 1.0085 - val_acc: 0.6515\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.0150 - acc: 0.6460 - val_loss: 0.9525 - val_acc: 0.6709\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "30336/50000 [=================>............] - ETA: 6s - loss: 2.1091 - acc: 0.2209"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 15s 305us/step - loss: 2.0027 - acc: 0.2666 - val_loss: 1.7351 - val_acc: 0.3806\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.6967 - acc: 0.3815 - val_loss: 1.5678 - val_acc: 0.4307\n",
            "Epoch 3/20\n",
            "35200/50000 [====================>.........] - ETA: 3s - loss: 1.5829 - acc: 0.4226"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.5707 - acc: 0.4273 - val_loss: 1.4761 - val_acc: 0.4608\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.4867 - acc: 0.4594 - val_loss: 1.3970 - val_acc: 0.4995\n",
            "Epoch 5/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.4328 - acc: 0.4830"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.4285 - acc: 0.4847 - val_loss: 1.3327 - val_acc: 0.5194\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.3729 - acc: 0.5081 - val_loss: 1.3215 - val_acc: 0.5309\n",
            "Epoch 7/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.3367 - acc: 0.5192"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.3274 - acc: 0.5227 - val_loss: 1.2368 - val_acc: 0.5636\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.2864 - acc: 0.5394 - val_loss: 1.2237 - val_acc: 0.5681\n",
            "Epoch 9/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.2589 - acc: 0.5516"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.2520 - acc: 0.5536 - val_loss: 1.1666 - val_acc: 0.5934\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.2186 - acc: 0.5672 - val_loss: 1.1379 - val_acc: 0.5988\n",
            "Epoch 11/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.1890 - acc: 0.5797"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.1848 - acc: 0.5800 - val_loss: 1.1024 - val_acc: 0.6099\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 1.1589 - acc: 0.5901 - val_loss: 1.0659 - val_acc: 0.6258\n",
            "Epoch 13/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.1237 - acc: 0.6006"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.1263 - acc: 0.6003 - val_loss: 1.0515 - val_acc: 0.6295\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.0981 - acc: 0.6138 - val_loss: 1.0247 - val_acc: 0.6414\n",
            "Epoch 15/20\n",
            "34944/50000 [===================>..........] - ETA: 3s - loss: 1.0822 - acc: 0.6192"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.0792 - acc: 0.6199 - val_loss: 1.0080 - val_acc: 0.6483\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.0501 - acc: 0.6314 - val_loss: 0.9976 - val_acc: 0.6474\n",
            "Epoch 17/20\n",
            "35456/50000 [====================>.........] - ETA: 3s - loss: 1.0237 - acc: 0.6398"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.0293 - acc: 0.6390 - val_loss: 0.9885 - val_acc: 0.6551\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.0097 - acc: 0.6457 - val_loss: 0.9518 - val_acc: 0.6668\n",
            "Epoch 19/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 0.9940 - acc: 0.6497"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 261us/step - loss: 0.9928 - acc: 0.6506 - val_loss: 0.9452 - val_acc: 0.6709\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 0.9671 - acc: 0.6618 - val_loss: 0.9069 - val_acc: 0.6836\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "30848/50000 [=================>............] - ETA: 6s - loss: 2.0559 - acc: 0.2381"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 15s 307us/step - loss: 1.9555 - acc: 0.2795 - val_loss: 1.7244 - val_acc: 0.3803\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.6917 - acc: 0.3799 - val_loss: 1.5689 - val_acc: 0.4344\n",
            "Epoch 3/20\n",
            "34944/50000 [===================>..........] - ETA: 3s - loss: 1.5990 - acc: 0.4144"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.5839 - acc: 0.4203 - val_loss: 1.5061 - val_acc: 0.4581\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.5112 - acc: 0.4513 - val_loss: 1.4090 - val_acc: 0.4925\n",
            "Epoch 5/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.4488 - acc: 0.4752"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 264us/step - loss: 1.4468 - acc: 0.4784 - val_loss: 1.3773 - val_acc: 0.5087\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.3914 - acc: 0.5011 - val_loss: 1.3596 - val_acc: 0.5144\n",
            "Epoch 7/20\n",
            "36224/50000 [====================>.........] - ETA: 3s - loss: 1.3482 - acc: 0.5169"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.3426 - acc: 0.5189 - val_loss: 1.2486 - val_acc: 0.5601\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.3007 - acc: 0.5363 - val_loss: 1.2077 - val_acc: 0.5724\n",
            "Epoch 9/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.2686 - acc: 0.5463"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.2612 - acc: 0.5506 - val_loss: 1.1999 - val_acc: 0.5720\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.2244 - acc: 0.5678 - val_loss: 1.1807 - val_acc: 0.5847\n",
            "Epoch 11/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 1.1950 - acc: 0.5754"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.1891 - acc: 0.5782 - val_loss: 1.1177 - val_acc: 0.6085\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.1571 - acc: 0.5907 - val_loss: 1.0744 - val_acc: 0.6252\n",
            "Epoch 13/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.1353 - acc: 0.5994"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.1288 - acc: 0.6009 - val_loss: 1.0480 - val_acc: 0.6304\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.1014 - acc: 0.6141 - val_loss: 1.0253 - val_acc: 0.6382\n",
            "Epoch 15/20\n",
            "35968/50000 [====================>.........] - ETA: 3s - loss: 1.0785 - acc: 0.6233"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.0755 - acc: 0.6225 - val_loss: 1.0192 - val_acc: 0.6450\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 1.0526 - acc: 0.6302 - val_loss: 1.0146 - val_acc: 0.6428\n",
            "Epoch 17/20\n",
            "35456/50000 [====================>.........] - ETA: 3s - loss: 1.0237 - acc: 0.6387"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 264us/step - loss: 1.0266 - acc: 0.6377 - val_loss: 0.9683 - val_acc: 0.6630\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.0062 - acc: 0.6467 - val_loss: 0.9238 - val_acc: 0.6776\n",
            "Epoch 19/20\n",
            "35712/50000 [====================>.........] - ETA: 3s - loss: 0.9910 - acc: 0.6507"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.9849 - acc: 0.6533 - val_loss: 0.9142 - val_acc: 0.6823\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.9688 - acc: 0.6583 - val_loss: 0.9086 - val_acc: 0.6785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fVUkk-43uWML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ee255a7a-91ce-4e53-f384-6511d5cdcea5"
      },
      "cell_type": "code",
      "source": [
        "# Load models and print results\n",
        "for e in [0.5,0.1,0.05,0.02,0.01]:\n",
        "    model = keras.models.load_model('cifra10_n'+str(e)+'.h5')\n",
        "    print('\\n  - Gaussian Noise with '+str(e)+' stdev:')\n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('\\tTest loss:\\t', scores[0])\n",
        "    print('\\tTest accuracy:\\t', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  - Gaussian Noise with 0.5 stdev:\n",
            "\tTest loss:\t 1.3755655250549317\n",
            "\tTest accuracy:\t 0.5045\n",
            "\n",
            "  - Gaussian Noise with 0.1 stdev:\n",
            "\tTest loss:\t 0.9894431276321412\n",
            "\tTest accuracy:\t 0.6573\n",
            "\n",
            "  - Gaussian Noise with 0.05 stdev:\n",
            "\tTest loss:\t 0.9525003180503845\n",
            "\tTest accuracy:\t 0.6709\n",
            "\n",
            "  - Gaussian Noise with 0.02 stdev:\n",
            "\tTest loss:\t 0.9068649646759033\n",
            "\tTest accuracy:\t 0.6836\n",
            "\n",
            "  - Gaussian Noise with 0.01 stdev:\n",
            "\tTest loss:\t 0.9086172308921814\n",
            "\tTest accuracy:\t 0.6785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JsJqBNCqmTso",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2) Add layers to the network to improve performance"
      ]
    },
    {
      "metadata": {
        "id": "W-q-pZF-mTso",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### First model: Add more layers and Adam optimizer"
      ]
    },
    {
      "metadata": {
        "id": "5QeWb-pFjSh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "3c5a257c-5201-4e83-cb59-8482e08c014e"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "#add another dense layer\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "                metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            shuffle=True)\n",
        "\n",
        "model.save('cifra10_moreLayersAdam.h5')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 14s 281us/step - loss: 1.5895 - acc: 0.4165 - val_loss: 1.2223 - val_acc: 0.5635\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.1792 - acc: 0.5793 - val_loss: 1.0421 - val_acc: 0.6345\n",
            "Epoch 3/20\n",
            " 8576/50000 [====>.........................] - ETA: 10s - loss: 1.0414 - acc: 0.6369"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.0193 - acc: 0.6391 - val_loss: 0.8829 - val_acc: 0.6917\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.9213 - acc: 0.6764 - val_loss: 0.8478 - val_acc: 0.7031\n",
            "Epoch 5/20\n",
            "28544/50000 [================>.............] - ETA: 5s - loss: 0.8579 - acc: 0.6940"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.8546 - acc: 0.6979 - val_loss: 0.8200 - val_acc: 0.7095\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.8112 - acc: 0.7127 - val_loss: 0.7611 - val_acc: 0.7309\n",
            "Epoch 7/20\n",
            "33920/50000 [===================>..........] - ETA: 4s - loss: 0.7674 - acc: 0.7303"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.7751 - acc: 0.7273 - val_loss: 0.7479 - val_acc: 0.7422\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.7347 - acc: 0.7405 - val_loss: 0.7356 - val_acc: 0.7473\n",
            "Epoch 9/20\n",
            "34176/50000 [===================>..........] - ETA: 3s - loss: 0.7095 - acc: 0.7513"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.7130 - acc: 0.7492 - val_loss: 0.7761 - val_acc: 0.7304\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.6892 - acc: 0.7569 - val_loss: 0.6814 - val_acc: 0.7634\n",
            "Epoch 11/20\n",
            "34176/50000 [===================>..........] - ETA: 4s - loss: 0.6517 - acc: 0.7705"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.6591 - acc: 0.7690 - val_loss: 0.6894 - val_acc: 0.7597\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.6441 - acc: 0.7739 - val_loss: 0.6948 - val_acc: 0.7610\n",
            "Epoch 13/20\n",
            "34688/50000 [===================>..........] - ETA: 3s - loss: 0.6136 - acc: 0.7852"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.6193 - acc: 0.7827 - val_loss: 0.6886 - val_acc: 0.7681\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.6146 - acc: 0.7839 - val_loss: 0.6615 - val_acc: 0.7747\n",
            "Epoch 15/20\n",
            "33664/50000 [===================>..........] - ETA: 4s - loss: 0.5818 - acc: 0.7939"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.5897 - acc: 0.7919 - val_loss: 0.6719 - val_acc: 0.7778\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.5764 - acc: 0.7965 - val_loss: 0.6341 - val_acc: 0.7816\n",
            "Epoch 17/20\n",
            "34688/50000 [===================>..........] - ETA: 3s - loss: 0.5616 - acc: 0.8036"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.5682 - acc: 0.7995 - val_loss: 0.6443 - val_acc: 0.7822\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.5514 - acc: 0.8075 - val_loss: 0.6664 - val_acc: 0.7775\n",
            "Epoch 19/20\n",
            "34176/50000 [===================>..........] - ETA: 4s - loss: 0.5421 - acc: 0.8088"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.5515 - acc: 0.8063 - val_loss: 0.6578 - val_acc: 0.7783\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.5250 - acc: 0.8133 - val_loss: 0.6395 - val_acc: 0.7869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gfdlXw0nlmWK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "ade1ca93-48c7-43b3-afbf-65f3c0dce0c2"
      },
      "cell_type": "code",
      "source": [
        "model= keras.models.load_model('cifra10_moreLayersAdam.h5')\n",
        "print('\\n  - More layers and Atom optimizer:')\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('\\tTest loss:\\t', scores[0])\n",
        "print('\\tTest accuracy:\\t', scores[1])\n",
        "\n",
        "Y_pred = model.predict(x_test, verbose=2)\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(Y_pred, axis=1))\n",
        "print('\\tConfusion Matrix:\\t')\n",
        "print(cm)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  - More layers and Atom optimizer:\n",
            "\tTest loss:\t 0.6395007309913635\n",
            "\tTest accuracy:\t 0.7869\n",
            "\tConfusion Matrix:\t\n",
            "[[824  16  55  13  15   3   7   7  37  23]\n",
            " [ 10 898   5   1   0   3   2   2  13  66]\n",
            " [ 67   3 685  53  64  48  51  15   6   8]\n",
            " [ 22   5  66 641  28 131  56  24  13  14]\n",
            " [ 11   3  54  70 739  27  50  41   3   2]\n",
            " [ 13   0  42 164  28 691  21  32   5   4]\n",
            " [ 12   5  47  52  11  17 846   3   5   2]\n",
            " [ 10   1  21  43  50  56   3 807   4   5]\n",
            " [ 72  22  12   8   6   3   5   4 855  13]\n",
            " [ 25  44   3  13   0   0   3   8  21 883]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MmxET6jumTsx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Second model: regularizer"
      ]
    },
    {
      "metadata": {
        "id": "ptxx_FTouWMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1765
        },
        "outputId": "5a9bc524-f234-499f-fc38-bb2754a95710"
      },
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "\n",
        "weight_decay = 1e-4\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            shuffle=True)\n",
        "\n",
        "model.save('cifra10_regL2.h5')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,32,15,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: dropout_13/cond/dropout/mul-1-TransposeNHWCToNCHW-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_13/cond/dropout/Floor, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training_5/RMSprop/gradients/dropout_14/cond/mul_grad/Shape/_1873 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_129_training_5/RMSprop/gradients/dropout_14/cond/mul_grad/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b82769f1adb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             shuffle=True)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifra10_regL2.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,32,15,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: dropout_13/cond/dropout/mul-1-TransposeNHWCToNCHW-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_13/cond/dropout/Floor, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training_5/RMSprop/gradients/dropout_14/cond/mul_grad/Shape/_1873 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_129_training_5/RMSprop/gradients/dropout_14/cond/mul_grad/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "kdaY9vZpuWMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "458a476f-42e8-4ad8-d86b-edb5e8ea60aa"
      },
      "cell_type": "code",
      "source": [
        "model= keras.models.load_model('cifra10_regL2.h5')\n",
        "print('\\n  - regularizer L2:')\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('\\tTest loss:\\t', scores[0])\n",
        "print('\\tTest accuracy:\\t', scores[1])\n",
        "\n",
        "Y_pred = model.predict(x_test, verbose=2)\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(Y_pred, axis=1))\n",
        "print('\\tConfusion Matrix:\\t')\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  - regularizer L2:\n",
            "\tTest loss:\t 0.8838677503585816\n",
            "\tTest accuracy:\t 0.7\n",
            "\tConfusion Matrix:\t\n",
            "[[714  26  41  25  17   5  15   9 103  45]\n",
            " [ 15 858   5  12   4   3  15   3  34  51]\n",
            " [ 65   8 535  72 112  67  90  25  14  12]\n",
            " [ 15   9  63 525  85 134 113  21  22  13]\n",
            " [ 22   4  52  53 656  21 108  61  17   6]\n",
            " [  5   4  57 201  57 552  61  47   8   8]\n",
            " [  4   3  33  43  33  10 855   5   8   6]\n",
            " [ 13   5  28  47  83  60  14 731   4  15]\n",
            " [ 48  33  10  15   6   8   9   3 845  23]\n",
            " [ 24 123   6  20   8   4  26  15  45 729]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XRymftMOmTs3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3) Try another method for dealing with overfitting"
      ]
    },
    {
      "metadata": {
        "id": "f2KL0hWjuWMO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "ef1229c0-3b18-4933-dd08-5b8d40a7126c"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            shuffle=True)\n",
        "\n",
        "model.save('cifra10_batch.h5')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 18s 366us/step - loss: 1.9586 - acc: 0.3018 - val_loss: 1.5445 - val_acc: 0.4519\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 17s 346us/step - loss: 1.5717 - acc: 0.4245 - val_loss: 1.3776 - val_acc: 0.4983\n",
            "Epoch 3/20\n",
            " 8576/50000 [====>.........................] - ETA: 13s - loss: 1.4671 - acc: 0.4692"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 347us/step - loss: 1.4354 - acc: 0.4785 - val_loss: 1.2801 - val_acc: 0.5419\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 17s 347us/step - loss: 1.3556 - acc: 0.5091 - val_loss: 1.2319 - val_acc: 0.5636\n",
            "Epoch 5/20\n",
            "29312/50000 [================>.............] - ETA: 6s - loss: 1.3001 - acc: 0.5316"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 346us/step - loss: 1.2909 - acc: 0.5355 - val_loss: 1.1479 - val_acc: 0.5922\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 18s 350us/step - loss: 1.2318 - acc: 0.5585 - val_loss: 1.1558 - val_acc: 0.5878\n",
            "Epoch 7/20\n",
            "34176/50000 [===================>..........] - ETA: 5s - loss: 1.1901 - acc: 0.5721"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 348us/step - loss: 1.1776 - acc: 0.5772 - val_loss: 1.0543 - val_acc: 0.6280\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 17s 349us/step - loss: 1.1312 - acc: 0.5970 - val_loss: 1.1196 - val_acc: 0.6025\n",
            "Epoch 9/20\n",
            "35328/50000 [====================>.........] - ETA: 4s - loss: 1.0907 - acc: 0.6129"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 347us/step - loss: 1.0855 - acc: 0.6142 - val_loss: 1.0090 - val_acc: 0.6449\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 17s 346us/step - loss: 1.0391 - acc: 0.6311 - val_loss: 0.9533 - val_acc: 0.6633\n",
            "Epoch 11/20\n",
            "35200/50000 [====================>.........] - ETA: 4s - loss: 1.0171 - acc: 0.6399"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 349us/step - loss: 1.0084 - acc: 0.6418 - val_loss: 0.9583 - val_acc: 0.6641\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 18s 350us/step - loss: 0.9709 - acc: 0.6527 - val_loss: 0.9303 - val_acc: 0.6743\n",
            "Epoch 13/20\n",
            "35328/50000 [====================>.........] - ETA: 4s - loss: 0.9443 - acc: 0.6664"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 348us/step - loss: 0.9379 - acc: 0.6685 - val_loss: 0.8368 - val_acc: 0.7038\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 17s 348us/step - loss: 0.9104 - acc: 0.6773 - val_loss: 0.8408 - val_acc: 0.7045\n",
            "Epoch 15/20\n",
            "35328/50000 [====================>.........] - ETA: 4s - loss: 0.8859 - acc: 0.6864"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 348us/step - loss: 0.8841 - acc: 0.6877 - val_loss: 0.8950 - val_acc: 0.6890\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 17s 349us/step - loss: 0.8611 - acc: 0.6959 - val_loss: 0.8247 - val_acc: 0.7083\n",
            "Epoch 17/20\n",
            "34944/50000 [===================>..........] - ETA: 4s - loss: 0.8429 - acc: 0.7023"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 350us/step - loss: 0.8404 - acc: 0.7033 - val_loss: 0.8125 - val_acc: 0.7171\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 18s 353us/step - loss: 0.8185 - acc: 0.7116 - val_loss: 0.7633 - val_acc: 0.7341\n",
            "Epoch 19/20\n",
            "34816/50000 [===================>..........] - ETA: 4s - loss: 0.8042 - acc: 0.7191"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 347us/step - loss: 0.8051 - acc: 0.7177 - val_loss: 0.7561 - val_acc: 0.7373\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 17s 346us/step - loss: 0.7813 - acc: 0.7225 - val_loss: 0.7757 - val_acc: 0.7313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L-1gJhvUuWMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7b9d437d-8685-409b-9405-6deb634c43f9"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = keras.models.load_model('cifra10_batch.h5')\n",
        "print('\\n  - Model with Batch Normalization:')\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('\\tTest loss:\\t', scores[0])\n",
        "print('\\tTest accuracy:\\t', scores[1])\n",
        "\n",
        "Y_pred = model.predict(x_test, verbose=2)\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(Y_pred, axis=1))\n",
        "print('\\tConfusion Matrix:\\t')\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  - Model with Batch Normalization:\n",
            "\tTest loss:\t 0.7756728023529053\n",
            "\tTest accuracy:\t 0.7313\n",
            "\tConfusion Matrix:\t\n",
            "[[740  11  72  13  44   6  18  24  51  21]\n",
            " [ 20 831   8  15   6   5  24   4  25  62]\n",
            " [ 46   1 580  34 151  52 104  21   7   4]\n",
            " [  8   3  57 451 111 181 150  29   8   2]\n",
            " [  7   2  28  25 817  12  75  30   4   0]\n",
            " [  5   0  48 147  96 625  42  33   3   1]\n",
            " [  3   0  26  30  38   5 893   1   4   0]\n",
            " [  8   1  37  18 104  49  16 766   0   1]\n",
            " [ 54  25  16  13  13   5  10   2 847  15]\n",
            " [ 37  59  10  21  21  12  19  23  35 763]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S7i58d-1uWMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1782
        },
        "outputId": "05719020-e89b-4627-b906-0aab2c204dfd"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import regularizers\n",
        "\n",
        "weight_decay = 1e-4\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            shuffle=True)\n",
        "\n",
        "model.save('cifra10_batch_regL2.h5')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,13,13,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/RMSprop/gradients/zeros_5-0-1-TransposeNCHWToNHWC-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/RMSprop/gradients/zeros_5, PermConstNCHWToNHWC-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training/RMSprop/gradients/dropout_5/cond/dropout/mul_grad/Shape/_297 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_506_training/RMSprop/gradients/dropout_5/cond/dropout/mul_grad/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8504c5eb4367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             shuffle=True)\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifra10_batch_regL2.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,13,13,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/RMSprop/gradients/zeros_5-0-1-TransposeNCHWToNHWC-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/RMSprop/gradients/zeros_5, PermConstNCHWToNHWC-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training/RMSprop/gradients/dropout_5/cond/dropout/mul_grad/Shape/_297 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_506_training/RMSprop/gradients/dropout_5/cond/dropout/mul_grad/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jpd39SHkuWMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7846c318-d1e4-4c98-d0b1-68d2ac078ce9"
      },
      "cell_type": "code",
      "source": [
        "model.save('cifra10_batch_regL2.h5')\n",
        "print('\\n  - Model with batch normalization and regularizer:')\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('\\tTest loss:\\t', scores[0])\n",
        "print('\\tTest accuracy:\\t', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  - Model with batch normalization and regularizer:\n",
            "\tTest loss:\t 0.8522795192718506\n",
            "\tTest accuracy:\t 0.7121\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}